{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ac4b47f-30a3-450e-bb1e-f38b814e86bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------------+--------------------+----------------+-------------+---------------------+\n",
      "|order_num|tracking_num|pck_recieved_date|package_deliver_date|          status|      address|last_update_timestamp|\n",
      "+---------+------------+-----------------+--------------------+----------------+-------------+---------------------+\n",
      "|     1000|     TRK1000|       2023-01-01|          2023-01-06|        Returned|   456 Oak St|  2023-01-01 05:41:55|\n",
      "|     1001|     TRK1001|       2023-01-01|          2023-01-06|      In Transit|  789 Pine St|  2023-01-01 08:43:50|\n",
      "|     1002|     TRK1002|       2023-01-01|          2023-01-05|Out for Delivery|   123 Elm St|  2023-01-01 17:44:29|\n",
      "|     1003|     TRK1003|       2023-01-01|          2023-01-04|      In Transit|  789 Pine St|  2023-01-01 05:29:16|\n",
      "|     1004|     TRK1004|       2023-01-01|          2023-01-02|         Delayed| 202 Birch Rd|  2023-01-01 13:12:49|\n",
      "|     1005|     TRK1005|       2023-01-01|          2023-01-03|       Delivered|101 Maple Ave|  2023-01-01 23:42:57|\n",
      "|     1006|     TRK1006|       2023-01-01|          2023-01-02|        Returned|101 Maple Ave|  2023-01-01 09:37:34|\n",
      "|     1007|     TRK1007|       2023-01-01|          2023-01-02|       Delivered|   456 Oak St|  2023-01-01 22:46:09|\n",
      "|     1008|     TRK1008|       2023-01-01|          2023-01-03|      In Transit|   123 Elm St|  2023-01-01 16:14:44|\n",
      "|     1009|     TRK1009|       2023-01-01|          2023-01-05|         Delayed| 202 Birch Rd|  2023-01-01 00:42:25|\n",
      "|     1010|     TRK1010|       2023-01-01|          2023-01-04|      In Transit| 202 Birch Rd|  2023-01-01 05:07:32|\n",
      "|     1011|     TRK1011|       2023-01-01|          2023-01-03|         Delayed|101 Maple Ave|  2023-01-01 03:21:20|\n",
      "|     1012|     TRK1012|       2023-01-01|          2023-01-02|      In Transit|   456 Oak St|  2023-01-01 03:45:31|\n",
      "|     1013|     TRK1013|       2023-01-01|          2023-01-02|       Delivered|   456 Oak St|  2023-01-01 15:17:46|\n",
      "|     1014|     TRK1014|       2023-01-01|          2023-01-02|         Delayed|101 Maple Ave|  2023-01-01 03:22:30|\n",
      "|     1015|     TRK1015|       2023-01-01|          2023-01-04|       Delivered|  789 Pine St|  2023-01-01 04:05:34|\n",
      "|     1016|     TRK1016|       2023-01-01|          2023-01-03|      In Transit| 202 Birch Rd|  2023-01-01 04:03:44|\n",
      "|     1017|     TRK1017|       2023-01-01|          2023-01-05|        Returned| 202 Birch Rd|  2023-01-01 19:03:48|\n",
      "|     1018|     TRK1018|       2023-01-01|          2023-01-02|         Delayed|   123 Elm St|  2023-01-01 06:16:24|\n",
      "|     1019|     TRK1019|       2023-01-01|          2023-01-03|       Delivered|   456 Oak St|  2023-01-01 19:31:06|\n",
      "+---------+------------+-----------------+--------------------+----------------+-------------+---------------------+\n",
      "\n",
      "Create Stage Table\n",
      "Data Inserted In Stage Table\n",
      "FileInfo(path='gs://order_tracking_new/input/order_tracking_2023_01_01.csv', name='order_tracking_2023_01_01.csv', size=1644, modificationTime=1702188600098) Moved in archive folder\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import *\n",
    "import os\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Data Ingestion\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "spark.conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "# Path to the service account JSON key in DBFS\n",
    "service_account_path = \"/dbfs/FileStore/shared_uploads/auth/noob2_bootcamp_b22d638cc5c5.json\"\n",
    "\n",
    "# Configure Spark to use the service account JSON key for GCS authentication\n",
    "spark.conf.set(\"fs.gs.auth.service.account.json.keyfile\", service_account_path)\n",
    "\n",
    "\n",
    "# GCS bucket details\n",
    "bucket_name = \"order_tracking_new\"\n",
    "data_directory = f\"gs://{bucket_name}/input/\"\n",
    "archive_directory = f\"gs://{bucket_name}/archive/\"\n",
    "\n",
    "# Define the path for the staging Delta table\n",
    "staging_table_path = \"dbfs:/user/hive/warehouse/staging_order_tracking\"\n",
    "\n",
    "# Read all CSV files from the specified GCS directory\n",
    "df = spark.read.csv(data_directory, inferSchema=True, header=True)\n",
    "\n",
    "df.show()\n",
    "\n",
    "print(\"Create Stage Table\")\n",
    "# Check if the Delta table exists\n",
    "if DeltaTable.isDeltaTable(spark, staging_table_path):\n",
    "    # If table exists, overwrite it\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(staging_table_path)\n",
    "else:\n",
    "    # If not, create the table\n",
    "    df.write.format(\"delta\").mode(\"append\").save(staging_table_path)\n",
    "\n",
    "print(\"Data Inserted In Stage Table\")\n",
    "\n",
    "# Create a table in the Hive Metastore\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS staging_order_tracking USING DELTA LOCATION '{staging_table_path}'\")\n",
    "\n",
    "# List and move files individually\n",
    "file_list = dbutils.fs.ls(data_directory)\n",
    "for file in file_list:\n",
    "    if file.name.endswith(\".csv\"):\n",
    "        print(f\"{file} Moved in archive folder\")\n",
    "        dbutils.fs.mv(file.path, os.path.join(archive_directory, file.name))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "stage_logistic_tracking_job",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
